{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(최종) 111_79_41_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Woori60/Auto-star-rating-tagging-method-using-SNS-review-data/blob/master/personal_111%20data_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fRBdfvIlWCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU로 바꾸기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkfBthQjls04",
        "colab_type": "code",
        "outputId": "e1999336-e3b6-4dd8-9fcc-cab0eb711439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnOdY38DbFjX",
        "colab_type": "code",
        "outputId": "9c77ccbc-4fed-494a-a6e3-96343b9b6706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ar6pGT-WAr",
        "colab_type": "code",
        "outputId": "c57fe241-46e3-4819-cb95-709f3c002b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#표제화 X\n",
        "#다시 돌릴 필요 X\n",
        "import json\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "n=WordNetLemmatizer()\n",
        "\n",
        "tx1 = ''\n",
        "tx2 = ''\n",
        "remove_list = ['NN', 'IN', 'DT', 'MD', 'TO', 'PR', 'CC', 'WD', 'WP']\n",
        "\n",
        "with open('/content/drive/My Drive/pretrained/user_review_15.json', 'rt', encoding='UTF-8') as f:\n",
        "    for line in f:\n",
        "        lineobj = json.loads(line)\n",
        "        tx1 = lineobj['text']       \n",
        "        tx3 = tx1.lower()\n",
        "        word_tokens = word_tokenize(tx3)\n",
        "\n",
        "        result = []\n",
        "        words = []\n",
        "        nword = []\n",
        "\n",
        "        tag_l = pos_tag(word_tokens)\n",
        "\n",
        "        for w in tag_l:\n",
        "          if w[1][:2] in remove_list:\n",
        "            continue\n",
        "          else:\n",
        "            words.append(w[0])\n",
        "        #print(words)\n",
        "        \n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        stop_words.update(['\\'re', '\\'d', '\\'t', '\\'ll', '\\'ve', '\\'s','\\'m', '!', '.', ',', '/', '?', '\\\"', '@', '%', '&', '*', '=','(',')','{','}', '-', '--', 'u', '...','$', '#', '*', '@', ':', ';', '[',']','~']) \n",
        "        stop_words.remove('not')\n",
        "        \n",
        "        for w in words:\n",
        "          if w == 'n\\'t':\n",
        "            w = 'not'\n",
        "          if w not in stop_words:\n",
        "            a = re.sub('[^a-zA-Z ]', '', w)\n",
        "            if a != '':\n",
        "              result.append(a) #result에 불용어 제거된 tokens 존재\n",
        "        \n",
        "        newresult=[]\n",
        "        for token in result:\n",
        "          shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "          tk = shortword.sub('', token)\n",
        "          if tk != '':\n",
        "            newresult.append(tk)\n",
        "        #print(newresult, '\\n')\n",
        "\n",
        "        tmpresult=[]\n",
        "        for review in newresult:\n",
        "          if review[:3] != 'www':\n",
        "            tmpresult.append(review)\n",
        "\n",
        "        #print(tmpresult)\n",
        "        newresult = tmpresult\n",
        "\n",
        "        # 길이 14 이상\n",
        "        notremove = ['unpretentious', 'unfortunately', 'approximately', 'complimentary', 'uncomfortable','disappointing']\n",
        "        lenreview = []\n",
        "        for review in newresult:\n",
        "          if len(review) >= 13 and review not in notremove :\n",
        "            continue\n",
        "          else:\n",
        "            lenreview.append(review)\n",
        "\n",
        "        newresult = lenreview\n",
        "\n",
        "        with open('/content/drive/My Drive/remove_only.txt', 'a', encoding='UTF-8') as mf:\n",
        "          mf.write('[\\n')\n",
        "          mf.write('\\n'.join(newresult))\n",
        "          mf.write('\\n]\\n')\n",
        "    \n",
        "f.close()          \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport json\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\nfrom nltk.stem import WordNetLemmatizer\\nfrom nltk.tag import pos_tag\\nimport re\\n\\nnltk.download(\\'punkt\\')\\nnltk.download(\\'averaged_perceptron_tagger\\')\\nnltk.download(\\'wordnet\\')\\nnltk.download(\\'stopwords\\')\\n\\nn=WordNetLemmatizer()\\n\\ntx1 = \\'\\'\\ntx2 = \\'\\'\\nremove_list = [\\'NN\\', \\'IN\\', \\'DT\\', \\'MD\\', \\'TO\\', \\'PR\\', \\'CC\\', \\'WD\\', \\'WP\\']\\n\\nwith open(\\'/content/drive/My Drive/pretrained/user_review_15.json\\', \\'rt\\', encoding=\\'UTF-8\\') as f:\\n    for line in f:\\n        lineobj = json.loads(line)\\n        tx1 = lineobj[\\'text\\']       \\n        tx3 = tx1.lower()\\n        word_tokens = word_tokenize(tx3)\\n\\n        result = []\\n        words = []\\n        nword = []\\n\\n        tag_l = pos_tag(word_tokens)\\n\\n        for w in tag_l:\\n          if w[1][:2] in remove_list:\\n            continue\\n          else:\\n            words.append(w[0])\\n        #print(words)\\n        \\n        stop_words = set(stopwords.words(\\'english\\'))\\n        stop_words.update([\\'\\'re\\', \\'\\'d\\', \\'\\'t\\', \\'\\'ll\\', \\'\\'ve\\', \\'\\'s\\',\\'\\'m\\', \\'!\\', \\'.\\', \\',\\', \\'/\\', \\'?\\', \\'\"\\', \\'@\\', \\'%\\', \\'&\\', \\'*\\', \\'=\\',\\'(\\',\\')\\',\\'{\\',\\'}\\', \\'-\\', \\'--\\', \\'u\\', \\'...\\',\\'$\\', \\'#\\', \\'*\\', \\'@\\', \\':\\', \\';\\', \\'[\\',\\']\\',\\'~\\']) \\n        stop_words.remove(\\'not\\')\\n        \\n        for w in words:\\n          if w == \\'n\\'t\\':\\n            w = \\'not\\'\\n          if w not in stop_words:\\n            a = re.sub(\\'[^a-zA-Z ]\\', \\'\\', w)\\n            if a != \\'\\':\\n              result.append(a) #result에 불용어 제거된 tokens 존재\\n        \\n        newresult=[]\\n        for token in result:\\n          shortword = re.compile(r\\'\\\\W*\\x08\\\\w{1,2}\\x08\\')\\n          tk = shortword.sub(\\'\\', token)\\n          if tk != \\'\\':\\n            newresult.append(tk)\\n        #print(newresult, \\'\\n\\')\\n\\n        tmpresult=[]\\n        for review in newresult:\\n          if review[:3] != \\'www\\':\\n            tmpresult.append(review)\\n\\n        #print(tmpresult)\\n        newresult = tmpresult\\n\\n        # 길이 14 이상\\n        notremove = [\\'unpretentious\\', \\'unfortunately\\', \\'approximately\\', \\'complimentary\\', \\'uncomfortable\\',\\'disappointing\\']\\n        lenreview = []\\n        for review in newresult:\\n          if len(review) >= 13 and review not in notremove :\\n            continue\\n          else:\\n            lenreview.append(review)\\n\\n        newresult = lenreview\\n\\n        with open(\\'/content/drive/My Drive/remove_only.txt\\', \\'a\\', encoding=\\'UTF-8\\') as mf:\\n          mf.write(\\'[\\n\\')\\n          mf.write(\\'\\n\\'.join(newresult))\\n          mf.write(\\'\\n]\\n\\')\\n    \\nf.close()          \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzMKvl7HHxvr",
        "colab_type": "code",
        "outputId": "f5574bfa-05ec-47f2-8917-f44136ca5e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "# 데이터 준비\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# token list 읽기 - 전체(이후에 분할)\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "\n",
        "# label 준비(1, 5)\n",
        "labelAll = []\n",
        "with open('/content/drive/My Drive/pretrained/user_review_15.json', 'rt', encoding='UTF-8') as f:\n",
        "    for line in f:\n",
        "        lineobj = json.loads(line)\n",
        "        star = lineobj['stars']\n",
        "        if star == 1 :\n",
        "          labelAll.append(0)\n",
        "        elif star == 5:\n",
        "          labelAll.append(1)\n",
        "\n",
        "f.close()\n",
        "label = np.array(labelAll)\n",
        "label = np_utils.to_categorical(label, num_classes=2)\n",
        "\n",
        "# data 준비\n",
        "result = []\n",
        "dataAll2 = []\n",
        "with open('/content/drive/My Drive/remove_only.txt', 'rt', encoding='UTF-8') as mf:\n",
        "  while True:\n",
        "    temp = mf.readline()\n",
        "    if not temp:\n",
        "      break\n",
        "    if temp == '[\\n':\n",
        "      continue\n",
        "    elif temp == ']\\n':\n",
        "      dataAll2.append(result)\n",
        "      result = []\n",
        "      continue\n",
        "    else:\n",
        "      l = len(temp)\n",
        "      word = temp[0:l-1]\n",
        "      result.append(word)\n",
        "\n",
        "mf.close()\n",
        "\n",
        "print('label size : ', len(label))\n",
        "print('data size : ', len(dataAll2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label size :  111\n",
            "data size :  111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBRxU0Bs-4xM",
        "colab_type": "code",
        "outputId": "edaa8160-f342-422e-f133-5c5464a80abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#다시 돌릴 필요X\n",
        "\n",
        "#word2vec 모델 생성\n",
        "embedding_dim = 300\n",
        "\n",
        "#train word2vec model\n",
        "embedding_model = Word2Vec(sentences=dataAll2, size=embedding_dim, min_count=2, window=4, iter=200, workers=4, sg=1) #size = embedding_dim = 80\n",
        "\n",
        "# load model\n",
        "filename = '/content/drive/My Drive/pretrained/GoogleNews-vectors-negative300.bin'\n",
        "embedding_model.intersect_word2vec_format(filename, binary=True)\n",
        "\n",
        "# save model\n",
        "filename = '/content/drive/My Drive/w2v_model_intersect_remove_15_final.txt'\n",
        "embedding_model.wv.save_word2vec_format(filename, binary=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#word2vec 모델 생성\\nembedding_dim = 300\\n\\n#train word2vec model\\nembedding_model = Word2Vec(sentences=dataAll2, size=embedding_dim, min_count=2, window=4, iter=200, workers=4, sg=1) #size = embedding_dim = 80\\n\\n# load model\\nfilename = '/content/drive/My Drive/pretrained/GoogleNews-vectors-negative300.bin'\\nembedding_model.intersect_word2vec_format(filename, binary=True)\\n\\n# save model\\nfilename = '/content/drive/My Drive/w2v_model_intersect_remove_15_final.txt'\\nembedding_model.wv.save_word2vec_format(filename, binary=False)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2odEfwfn-8ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pretrained model\n",
        "embeddings_index = {}\n",
        "file = open(os.path.join('', '/content/drive/My Drive/w2v_model_intersect_remove_15_final.txt'), encoding=\"utf-8\")\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:])\n",
        "  embeddings_index[word] = coefs\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzvIsWSYNf7w",
        "colab_type": "code",
        "outputId": "d7a3ab72-7e0f-4db7-9904-ac001df13a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 전체 데이터 학습(6)/검증(1)/테스트(3)\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# train_test_split\n",
        "# Stratified하게 트레이닝셋과 테스트셋으로 나눈다(1회만 실시)\n",
        "from sklearn.model_selection import train_test_split\n",
        "seed = 777\n",
        "dataAll2 = np.array(dataAll2)\n",
        "train_index, test_index = train_test_split(np.array(range(dataAll2.shape[0])), shuffle=True, stratify=label, test_size=0.3, random_state=seed)\n",
        "\n",
        "x_train, X_test = dataAll2[train_index], dataAll2[test_index]\n",
        "y_train, Y_test = label[train_index], label[test_index]\n",
        "print(\"-\"*40)\n",
        "\n",
        "print('테스트 : ', len(X_test), ', ', len(Y_test))\n",
        "\n",
        "train_index, valid_index = train_test_split(np.array(range(x_train.shape[0])), shuffle=True, stratify=y_train, test_size=0.1, random_state=seed)\n",
        "\n",
        "X_train, X_valid = x_train[train_index], x_train[valid_index]\n",
        "Y_train, Y_valid = y_train[train_index], y_train[valid_index]\n",
        "print(\"-\"*40)\n",
        "print('학습 : ', len(X_train), ', ', len(Y_train))\n",
        "print(\"-\"*40)\n",
        "print('검증 : ', len(X_valid), ', ', len(Y_valid))\n",
        "print(\"-\"*40)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "테스트 :  34 ,  34\n",
            "----------------------------------------\n",
            "학습 :  69 ,  69\n",
            "----------------------------------------\n",
            "검증 :  8 ,  8\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlNgkz_iL6-k",
        "colab_type": "code",
        "outputId": "6c0ab691-89bc-4e54-a3e4-eadd059444c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# max_length - train data\n",
        "train_sum=0\n",
        "train_count = len(X_train)\n",
        "for sent in X_train :\n",
        "  train_sum = train_sum+len(sent)\n",
        "\n",
        "test_count = len(X_test)\n",
        "for sent in X_test :\n",
        "  train_sum = train_sum+len(sent)\n",
        "\n",
        "valid_count = len(X_valid)\n",
        "for sent in X_test :\n",
        "  train_sum = train_sum+len(sent)\n",
        "\n",
        "MAX = train_sum / (train_count + test_count + valid_count)\n",
        "\n",
        "MAX = int(MAX)\n",
        "print(MAX)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lbq4v75OcC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_train=[]\n",
        "for review in X_train:\n",
        "  if len(review) > 49:\n",
        "    tmp_train.append(review[0:50])\n",
        "  else:\n",
        "    tmp_train.append(review)\n",
        "X_train = tmp_train\n",
        "\n",
        "tmp_test=[]\n",
        "for review in X_test:\n",
        "  if len(review) > 49:\n",
        "    tmp_test.append(review[0:50])\n",
        "  else:\n",
        "    tmp_test.append(review)\n",
        "X_test = tmp_test\n",
        "\n",
        "\n",
        "tmp_valid=[]\n",
        "for review in X_valid:\n",
        "  if len(review) > 49:\n",
        "    tmp_valid.append(review[0:50])\n",
        "  else:\n",
        "    tmp_valid.append(review)\n",
        "X_valid = tmp_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdvSXtfMTeGA",
        "colab_type": "code",
        "outputId": "624d58ba-6832-41d5-bf2f-0888e8308a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n",
            "34\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FloYtgbY7QK",
        "colab_type": "code",
        "outputId": "5c7cd214-05a6-43b8-a760-9e83518e8ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "\n",
        "#########################################\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(dataAll2)\n",
        "sequences_obj = tokenizer_obj.texts_to_sequences(dataAll2)\n",
        "word_index = tokenizer_obj.word_index\n",
        "num_words = len(word_index)+1\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None :\n",
        "    # words not found in embedding index will be all-zeros\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "##########################################\n",
        "\n",
        "\n",
        "# vec - train data\n",
        "tokenizer_obj_train = Tokenizer()\n",
        "tokenizer_obj_train.fit_on_texts(X_train)\n",
        "sequences_train = tokenizer_obj_train.texts_to_sequences(X_train)\n",
        "\n",
        "# vec - test data\n",
        "tokenizer_obj_test = Tokenizer()\n",
        "tokenizer_obj_test.fit_on_texts(X_test)\n",
        "sequences_test = tokenizer_obj_test.texts_to_sequences(X_test)\n",
        "\n",
        "# vec - valid data\n",
        "tokenizer_obj_valid = Tokenizer()\n",
        "tokenizer_obj_valid.fit_on_texts(X_valid)\n",
        "sequences_valid = tokenizer_obj_valid.texts_to_sequences(X_valid)\n",
        "\n",
        "\n",
        "# pad_sequences_train\n",
        "word_index_train = tokenizer_obj_train.word_index\n",
        "print('Found %s unique tokens.' % len(word_index_train))\n",
        "\n",
        "review_pad_train = pad_sequences(sequences_train, maxlen=MAX, padding = 'post')         # test data max가 더 커서 그 값으로 train, test 둘다 패딩\n",
        "sentiment_train = Y_train\n",
        "\n",
        "print('Shape of review tensor:', review_pad_train.shape)\n",
        "print('Shape of sentiment tensor:', sentiment_train.shape)\n",
        "\n",
        "num_words_train = len(word_index_train)+1\n",
        "embedding_dim = 300\n",
        "embedding_matrix_train = np.zeros((num_words_train, embedding_dim))\n",
        "\n",
        "for word, i in word_index_train.items():\n",
        "  if i > num_words_train:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None :\n",
        "    # words not found in embedding index will be all-zeros\n",
        "    embedding_matrix_train[i] = embedding_vector\n",
        "\n",
        "print('train data word size : ',num_words_train)\n",
        "\n",
        "# pad_sequences_test\n",
        "word_index_test = tokenizer_obj_test.word_index\n",
        "print('Found %s unique tokens(test).' % len(word_index_test))\n",
        "\n",
        "review_pad_test = pad_sequences(sequences_test, maxlen=MAX, padding = 'post')   # test data max가 더 커서 그 값으로 train, test 둘다 패딩\n",
        "sentiment_test = Y_test\n",
        "\n",
        "print('Shape of review tensor(test):', review_pad_test.shape)\n",
        "print('Shape of sentiment tensor(test):', sentiment_test.shape)\n",
        "\n",
        "num_words_test = len(word_index_test)+1\n",
        "embedding_matrix_test = np.zeros((num_words_test, embedding_dim))\n",
        "\n",
        "for word, i in word_index_test.items():\n",
        "  if i > num_words_test:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None :\n",
        "    # words not found in embedding index will be all-zeros\n",
        "    embedding_matrix_test[i] = embedding_vector\n",
        "\n",
        "print('test data word size : ',num_words_test)\n",
        "\n",
        "# pad_sequences_valid\n",
        "word_index_valid = tokenizer_obj_valid.word_index\n",
        "print('Found %s unique tokens(valid).' % len(word_index_valid))\n",
        "\n",
        "review_pad_valid = pad_sequences(sequences_valid, maxlen=MAX, padding = 'post')   # test data max가 더 커서 그 값으로 train, test 둘다 패딩\n",
        "sentiment_valid = Y_valid\n",
        "\n",
        "print('Shape of review tensor(valid):', review_pad_valid.shape)\n",
        "print('Shape of sentiment tensor(valid):', sentiment_valid.shape)\n",
        "\n",
        "num_words_valid = len(word_index_valid)+1\n",
        "embedding_matrix_valid = np.zeros((num_words_valid, embedding_dim))\n",
        "\n",
        "for word, i in word_index_valid.items():\n",
        "  if i > num_words_valid:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None :\n",
        "    # words not found in embedding index will be all-zeros\n",
        "    embedding_matrix_valid[i] = embedding_vector\n",
        "\n",
        "print('valid data word size : ',num_words_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 942 unique tokens.\n",
            "Shape of review tensor: (69, 49)\n",
            "Shape of sentiment tensor: (69, 2)\n",
            "train data word size :  943\n",
            "Found 535 unique tokens(test).\n",
            "Shape of review tensor(test): (34, 49)\n",
            "Shape of sentiment tensor(test): (34, 2)\n",
            "test data word size :  536\n",
            "Found 195 unique tokens(valid).\n",
            "Shape of review tensor(valid): (8, 49)\n",
            "Shape of sentiment tensor(valid): (8, 2)\n",
            "valid data word size :  196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pScq85P8Jjji",
        "colab_type": "code",
        "outputId": "9be9132a-b15e-4b1d-ea02-973382332e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "### code part3 - 훈련 모델\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, Conv1D, MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "#model.reset_states()\n",
        "# define model\n",
        "# In the below code, the only change from previous model is using the embedding_matrix as input to the Embedding layer and setting trainable = False, since the embedding is already learned.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words, embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=MAX, trainable = False))    #test data max length로 맞춤\n",
        "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=16 , kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 49, 300)           402300    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 47, 16)            14416     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 23, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 22, 16)            528       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 11, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 10, 32)            1056      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               41088     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 467,774\n",
            "Trainable params: 467,774\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA6b4dsaD0lZ",
        "colab_type": "code",
        "outputId": "bfb6bf39-2121-4ac6-cce9-d7e411e8cf21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result = model.fit(review_pad_train, sentiment_train, batch_size=6, epochs=30, validation_data=(review_pad_valid, sentiment_valid), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 69 samples, validate on 8 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "69/69 [==============================] - 2s 35ms/step - loss: 0.6976 - acc: 0.4638 - val_loss: 0.6932 - val_acc: 0.5000\n",
            "Epoch 2/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6835 - acc: 0.6232 - val_loss: 0.6976 - val_acc: 0.5000\n",
            "Epoch 3/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.6505 - acc: 0.6667 - val_loss: 0.7072 - val_acc: 0.4375\n",
            "Epoch 4/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.5748 - acc: 0.8623 - val_loss: 0.7225 - val_acc: 0.4375\n",
            "Epoch 5/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.3496 - acc: 0.9565 - val_loss: 0.7997 - val_acc: 0.5000\n",
            "Epoch 6/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1284 - acc: 0.9855 - val_loss: 0.9579 - val_acc: 0.5000\n",
            "Epoch 7/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0580 - acc: 0.9855 - val_loss: 1.4566 - val_acc: 0.5000\n",
            "Epoch 8/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.1807 - val_acc: 0.6250\n",
            "Epoch 9/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.4178 - val_acc: 0.6250\n",
            "Epoch 10/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0286 - acc: 0.9855 - val_loss: 1.2582 - val_acc: 0.6250\n",
            "Epoch 11/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.7548 - val_acc: 0.5000\n",
            "Epoch 12/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.7333 - val_acc: 0.5000\n",
            "Epoch 13/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.4963 - val_acc: 0.5000\n",
            "Epoch 14/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.4194 - val_acc: 0.4375\n",
            "Epoch 15/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 5.8132e-04 - acc: 1.0000 - val_loss: 1.4004 - val_acc: 0.4375\n",
            "Epoch 16/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 5.2069e-04 - acc: 1.0000 - val_loss: 1.3962 - val_acc: 0.5000\n",
            "Epoch 17/30\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5674e-04 - acc: 1.0000 - val_loss: 1.4746 - val_acc: 0.3750\n",
            "Epoch 18/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 8.7385e-04 - acc: 1.0000 - val_loss: 1.5448 - val_acc: 0.5000\n",
            "Epoch 19/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 4.0303e-04 - acc: 1.0000 - val_loss: 1.5170 - val_acc: 0.3750\n",
            "Epoch 20/30\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.8484 - val_acc: 0.5000\n",
            "Epoch 21/30\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0193e-04 - acc: 1.0000 - val_loss: 1.9763 - val_acc: 0.5625\n",
            "Epoch 22/30\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9303e-04 - acc: 1.0000 - val_loss: 1.8598 - val_acc: 0.5000\n",
            "Epoch 23/30\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.5874 - val_acc: 0.5000\n",
            "Epoch 24/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 9.2623e-05 - acc: 1.0000 - val_loss: 1.4936 - val_acc: 0.5000\n",
            "Epoch 25/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.8858 - val_acc: 0.5000\n",
            "Epoch 26/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 4.3333e-04 - acc: 1.0000 - val_loss: 1.9051 - val_acc: 0.5000\n",
            "Epoch 27/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.5017e-04 - acc: 1.0000 - val_loss: 1.8390 - val_acc: 0.5000\n",
            "Epoch 28/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 2.1653e-04 - acc: 1.0000 - val_loss: 1.7599 - val_acc: 0.5000\n",
            "Epoch 29/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.5634e-04 - acc: 1.0000 - val_loss: 1.6452 - val_acc: 0.5000\n",
            "Epoch 30/30\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.5895e-04 - acc: 1.0000 - val_loss: 1.5909 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIicBTMYEnme",
        "colab_type": "code",
        "outputId": "0f09fba4-dfbe-424f-8692-812eebc9de4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "#loss, accuracy = model.evaluate(padded_sentences_test, test_label, verbose=1)\n",
        "loss, accuracy = model.evaluate(review_pad_test, sentiment_test, batch_size=6, verbose=1)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(result.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(result.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([-0.2, 1.2])\n",
        "\n",
        "acc_ax.plot(result.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(result.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([-0.2, 1.2])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 0s 2ms/step\n",
            "Accuracy: 55.882352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAEKCAYAAACRwxtAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXgUVfbw8e/JRhYSloRNQEBAZEdZ\nZAQBtxFQQEVERxkZFcbfuIyvjgPjGndcZ0RxBBwUFWVQFDcERVlkFAWRVUB2CbIlJIEkhCx93j+q\nAwGydJJObzmf56mH7q6qW6e69Z7cqlv3iqpijDHGhJIwfwdgjDHGeJslN2OMMSHHkpsxxpiQY8nN\nGGNMyLHkZowxJuRYcjPGGBNy/JrcRGSaiOwXkXWlrL9eRNaIyFoR+VZEuvo6RmOMMcFXX/u75fYG\nMLCM9duB/qraGXgMmOKLoIwxxpziDYKovo7w58FVdYmItCxj/bfF3i4DmlV3TMYYY04VbPW1X5Nb\nBd0MfF7SChEZC4x1v+0eGxvrs6CCTl4eFBRAZb6jggJnf4CwMIiO9m5sxhi/ycnJUWBlsY+mqGpl\nW1+l1te+EhTJTUQuwPmy+pa03v0DTAGIi4vT7OxsH0YXZIYPh/XrYePGiu+7Zw+cdprz+tln4e67\nvRubMcZvROSIqvbwQjll1te+4u97buUSkS7Aa8AwVU3zdzxBb+tWaN26cvs2aQJt2zqvBw3yXkzG\nmJAQSPV1QCc3ETkd+AAYpaq/+DueoKcK27ZVPrkBDB0KnTvDWWd5Ly5jTNALtPpa/DkrgIi8CwwA\nkoB9wMNAJICqvioirwHDgZ3uXQrKazbbZckyHDgADRvCP/8Jd91VuTJcLigshMhI78ZmjPErEclR\n1bgy1nu9vq5Ofk1u1aGk5Jafn09KSgq5ubl+iipAHD0Ke/dCgwYV7lASHR1Ns2bNiLSkZkxIKi+5\nBZug6FBSVSkpKcTHx9OyZUtExN/h+E9amtPjsUMHiInxeDdVJS0tjZSUFFq1alWNARpjjHcE9D03\nb8nNzSUxMbFmJzZwWm4AtWpVaDcRITEx0Vq+xpigUSOSG2CJDZzkFhnpPKNWQfb9GWOCSY1JbgYn\nuVWw1WaMMcHIkpsPZGRk8Morr1Rq38GDB5ORkeHx9snJyTz33HMlr7TkZoypISy5+UBZya2goKDM\nfefOnUvdunWrHoTLBfn5ltyMMTWCJTcfGD9+PFu3bqVbt27ce++9LFq0iPPPP5+hQ4fSoUMHAK64\n4gq6d+9Ox44dmTLl+HBuLVu2JDU1lR07dtC+fXvGjBlDx44d+f3vf8+RI0fKPO6qVavo3bs3Xbp0\n4corriD90CGoVYuJEyfSoUMHunTpwrXXXgvA4sWL6datG926dePss8/m8OHD1feFGGNMNasRjwIU\nt3nzXWRlrfJqmbVrd6Nt23+Vun7ChAmsW7eOVauc4y5atIiVK1eybt26Y13rp02bRv369Tly5Ag9\ne/Zk+PDhJCYmnhT7Zt59912mTp3KNddcw+zZs7nhhhtKPe4f//hHXnrpJfr3789Df/87j0ydyr+m\nTmXChAls376dWrVqHbvk+dxzzzFp0iT69OlDVlYW0TYosjEmiFnLzU969ep1wjNjEydOpGvXrvTu\n3Ztdu3axefPmU/Zp1aoV3bp1A6B79+7s2LGj1PIzMzPJyMigf//+ANw4fDhLfvoJatWiS5cuXH/9\n9bz99ttERDh/3/Tp04e7776biRMnkpGRcexzY4wJRjWuBiurheVLcXHHBwJYtGgRCxYs4LvvviM2\nNpYBAwaU+ExZrWL3y8LDw8u9LHmCoqlqIiL47LPPWLJkCZ988glPPPEEa9euZfz48Vx22WXMnTuX\nPn36MH/+fM6y8SONMUHKWm4+EB8fX+Y9rMzMTOrVq0dsbCwbN25k2bJlVT5mnTp1qFevHt988w0A\nb82aRf9evXCpsmvXLi644AKefvppMjMzycrKYuvWrXTu3Jlx48bRs2dPNlZmShxjjAkQNa7l5g+J\niYn06dOHTp06MWjQIC677LIT1g8cOJBXX32V9u3b065dO3r37u2V406fPp1bb72VnJwczkhK4vVn\nn6WwsJAbbriBzMxMVJU777yTunXr8uCDD7Jw4ULCwsLo2LEjg2xKG2NMEKsRAydv2LCB9u3b+ymi\nAKAKK1dCo0bQrPIzv9f479GYEBZqAyfbZcmaID/fSXD2jJsxpoaw5FYTVHLAZGOMCVaW3GqCop6X\nltyMMTWEJbeaIC8PRCAqyt+RGGOMT1hyqwlyc53EZtPWGGNqCEtuNYHNBmCMqWEsuQWo2rVrV+jz\nMuXlWXIzxtQoltxCXUGBs1hyM8bUIJbcfGD8+PFMmjTp2PuiCUWzsrK46KKLOOecc+jcuTMfffSR\nx2WqKvfeey+dOnWic+fO/Pe//wVgz5499OvXj27dutGpUye++fprCgsLGX333ce2/ec//+n1czTG\nmEDi1+G3RGQacDmwX1U7lbBegBeBwUAOMFpVV1bpoHfdBau8O+UN3brBv0ofkHnkyJHcdddd3Hbb\nbQDMmjWL+fPnEx0dzYcffkhCQgKpqan07t2boUOHIh50/Pjggw9YtWoVq1evJjU1lZ49e9KvXz/e\neecdLr30Uu6//34KCwvJSUlh1ZIl7N67l3Xr1gFUaGZvY4wBP9XXVeDvltsbwMAy1g8C2rqXscC/\nfRCT15199tns37+f3377jdWrV1OvXj2aN2+OqnLffffRpUsXLr74Ynbv3s2+ffs8KnPp0qVcd911\nhIeH06hRI/r378/y5cvp2bMnr7/+OsnJyaxdu5b4qCjOaNqUbTt3cscddzBv3jwSEhKq+YyNMSHo\nDYKovvZry01Vl4hIyzI2GQa8qc4AmMtEpK6INFHVPZU+aBktrOo0YsQI3n//ffbu3cvIkSMBmDFj\nBgcOHODHH38kMjKSli1bljjVTUX069ePJUuW8NlnnzF69GjuHjWKP150EatXr2b+/Pm8+uqrzJo1\ni2nTplW47Lw84Ycf4NdfPds+LAzat4d27ZzXVbV7N/z00/Fn0o0xJ6pfHy68sHrK9kt9XQWBPitA\nU2BXsfcp7s9O+LJEZCzOXwpEBeiDyiNHjmTMmDGkpqayePFiwJnqpmHDhkRGRrJw4UJ27tzpcXnn\nn38+kydP5sYbb+TgwYMsWbKEZ599lp07d9KsWTPGjBnD0aNHWbl8OYN/9zuiXC6GDx9Ou3btypy9\nu4gqbN0K338PP/zg/Lty5Znk51f83OvUgZ494dxznaVXL2cM57JkZcGKFScef/fuih/bmJrk3HOh\nCjNmRYjIimLvp6jqlArs71F97SuBntw84v4BpoAzK4CfwylRx44dOXz4ME2bNqVJkyYAXH/99QwZ\nMoTOnTvTo0ePCk0OeuWVV/Ldd9/RtWtXRIRnnnmGxo0bM336dJ599lkiIyOJi4vnxdseZN2OLO68\n9QpcLhcADzzwHKmpJ5aXlwerVx9PJD/8AGlpzrrYWOjRA0aNSmfw4ETatvWsJZaXB2vWOOV9/z1M\nmACFhc66Fi2OJ7tzz4X4+OPH/v57WL8e3OHSpg307+9s16MH2FVVY0oWE1Ol3QtUtYeXQvE7v095\n427mflrKDcrJwCJVfdf9fhMwoKxmrk15AxkZ8Prr8PLLyrZtFRuVRAQ6djzewjr3XOd9RETVv8ec\nHGfmnaIE9sMPcHJjtX7948ctiiExsdKHNMZ4yJMpb7xdX1enQG+5fQzcLiIzgXOBTH99UcFgwwZ4\n+WWYPh2ys6Hvecrtw1KIbFgPynn4u+j+WI8eTiuqOsTGQt++zlJk714nyWVlOZcu27SxUcKMCVIB\nVV/7+1GAd4EBQJKIpAAPA5EAqvoqMBenW+kWnK6lf/JPpIHL5YLPP4eJE+GLL5xnta+7Du64A85p\nfRg274N2daGaElZVNW4MQ4f6OwpjTHmCrb72d2/J68pZr8BtXjqWR8+PBYvMTHjjDXjpJafjR9Om\n8MQTMGYMNGjg3mi/9+Zx8/fla2OMf/myvvaGQL8s6RXR0dGkpaWRmJgY9AkuPx/GjYOpU51LeX36\nwJNPwpVXQmTkSRvn5jrXG09ZUTGqSlpaGtHR0VUqxxhjfMXvHUq8raQOJfn5+aSkpFT5GbJAMHFi\nA159NYkhQzL54x8P0rFjKeek6vSdj4wsv9+9B6Kjo2nWrBmRVUyUxpjA5EmHkmBSI5JbqFiyBC64\nAP74R6c3ZJnefx9GjICPPrKbWsaYcllyC3ChmtzS06FrV+f22cqVHvRo7NcPdu2CLVsgPNwnMRpj\ngleoJbcacc8t2KnCrbfCnj3w7bceJLZVq+Cbb+DZZy2xGWNqJEtuQeCNN2DWLHjqKedZsHK99JLz\nUNnNN1d3aMYYE5DssmSA27wZzj7bGanjyy89aIilpUGzZs6NucmTfRKjMSb4hdplSX9PeWPKkJcH\nf/gDREXBm296eIXxtdecRwDuuKPa4zPGmEBllyUD2EMPOSPjz57tNMbKVVAAkyY5XSo7nTL0mzHG\n1BjWcgtQX38NzzzjjDhy1VUe7vTxx04PSWu1GWNqOLvnFoDS0qBLF6dX5I8/QpynV8EvuAC2b3e6\n/0dYo9wY4zm752aqlSrccgscOADvvluBxLZmDSxaBH/5iyU2Y0yNZ7VggJk6FebMgeeec3pJeuzl\nlyE62rr/G2MMdlkyoGzYAN27O/OdzZvn2WzXABw86PQ4uf56JzsaY0wF2WVJUy2OHnXmYYuLcyYb\n9TixAfznP3DkiHUkMcYYN7ssGSAmTIDVq50Oj02aVGDHwkJ45RXo39/phWKMMcZaboHA5YJp02Dg\nQBgypII7f/op7NhhrTZjjCnGklsAWLYMfv3VGY2kwiZOhObNYdgwr8dljDHBypJbAJg50+noWOH8\ntH6987S3df83xpgTWHLzs4ICZ8T/yy6DhIQK7vzyy84Eb7fcUi2xGWNMsLLk5meLF8O+fXDttRXc\nMT3dGU35D3+ApKRqic0YY4KVJTc/e/ddqF3bablVyOuvQ06OdSQxxpgS+DW5ichAEdkkIltEZHwJ\n608XkYUi8pOIrBGRwf6Is7rk5Tkj/l9xBcTEVGDHwkJn9P++fSs4jIkxxlReMNXZfktuIhIOTAIG\nAR2A60Skw0mbPQDMUtWzgWuBV3wbZfWaPx8yMpyHtytk7lzYtg3uvLNa4jLGmJMFW53tz5ZbL2CL\nqm5T1TxgJnByf0EFirpZ1AF+82F81W7mTKhfHy6+uII7vvQSNG3qNPmMMcY3gqrO9mdyawrsKvY+\nxf1ZccnADSKSAswFSrzBJCJjRWSFiKwoKCiojli9LicHPvoIrr7amWnbY++/D19+6XT/j4ystviM\nMTVORFE96l7GnrTea3W2LwR6h5LrgDdUtRkwGHhLRE6JWVWnqGoPVe0RESTPe336KWRnV7CX5P/+\nBzfcAOedB//v/1VbbMaYGqmgqB51L1MqUYZHdbYv+DO57QaaF3vfzP1ZcTcDswBU9TsgGgiJfu8z\nZzpjSPbr5+EOv/wCQ4fC6ac7A1BWqAeKMcZUWVDV2f5MbsuBtiLSSkSicG4+fnzSNr8CFwGISHuc\nL+qAT6OsBpmZTp+Qa66B8HAPdti/HwYNcjb+/HNITKz2GI0x5iRBVWf77RqeqhaIyO3AfCAcmKaq\n60XkUWCFqn4M3ANMFZH/h3OjcrSGwAR0c+Y4U9x4dEkyOxsuvxz27IGFC6F162qPzxhjThZsdbZN\nVuoHgwbBxo1Ob36RMjYsLISrroJPPoEPP7TBkY0x1cYmKzVVcuCA09nx2mvLSWyq8Ne/OvfXJk60\nxGaMMRVgyc3HZs92GmTlPrj9wgvOKCR/+xvcfrtPYjPGmFBhlyV9rH9/p/W2fn0ZLbdZs2DkSBgx\nwulWGWZ/gxhjqpddljSVlpIC33zjtNpKTWzffAOjRkGfPs6o/5bYjDGmwqzm9KFZs5xbaSNHlrLB\npk3OvbWWLZ3hS6KjfRmeMcaEDLss6UO9ejn32378sYSV27Y5g0xmZ8N338EZZ/g8PmNMzRVqlyWD\nY6yqELB1KyxfDs8+izP99po18O23zpBa334Lv/7qjDqyeLElNmOMqSJLbr6Qns7MRw8AZ3LNh9dB\n8idOCw2c0f379IF77nEegGvb1q+hGmNMKLDk5i2FhU6Pkc2bYcuW48umTbBxIzNZQ1+WcvrRzXDT\nTc7gx336QPPm5ZdtjDGmQiy5uakqe/b8h/j4s4mL60xYWFTRCjh8GNLTnSUjw/l3z57jCWzzZuee\nWV7e8QKjo52hss46i3WX/D/WvdSZl58/Cnev8M8JGmNMDWLJze3onjVE/GEM+VmQfViIzIkiMgvC\nDuUhrlI63cTEQJs20KGDM2J/mzbOZcU2beC0045145/5gPNyxA21fHhGxhhTc1lyc6sV15KkPWdQ\nGB9OXpMCcmKyyY1OJ7+2kh8PrvhaRDZsQ1SjTsSc1p24VpdQq2XXcsbQchp+M2fCRRdBw4Y+Ohlj\njKnhLLm5SZ06yKathAGRQBygWkhOzkYOHVrO4cPLOXh4OVlZH6L6X+TXSBrn3cjpp/+DmJjSezeu\nWOH0lLzvPl+diTHGGHvOrYJcrqNkZa1h797p7NnzGqoFNGp0Ay1a3Eds7JmnbH/PPfDSS86UbHXr\nVltYxhhTJaH2nJsltyo4evQ3du16jt9+exWX6ygNG46kRYv7iYvrCDh9Tzp1gu7dnQFHjDEmUFly\nC3D+GKEkL28/u3Y9z+7dk3C5cmjQYDhr1jzDPfe0Yt8++OwzGDjQpyEZY0yFWHILcP4cfis/P42f\nfnqNcePasWjRFZx55nYmTz7CgAEd/BKPMcZ4KtSSmw2c7CWq8NZbiVx66Ti++24Y9977FZMnnwt0\nZOfOCf4OzxhjahTrLekFW7fC2LHw9ddw/vkwdarQrt1FFBRs4Zdf/sz27f8gKqoxTZqM9neoxhhT\nI1jLrQoKCuC556BzZ6fL/6uvwqJF0K6dsz4iIoGzzppOvXqXsGnTLaSlfe7XeI0xpqawe26VtGoV\n3HKLM33N0KHwyivOGMglKSg4zKpV/cnJ2US3botISOhZ7fFVF1UlNScVxbv/3dSLrkdkeKRXyzTG\neC7U7rlZcquEt9+G0aMhMdF5hm3EiHIHKuHo0b389NPvKCzM5uyzvyU2tk21xlhd7ph7By8vf9nr\n5XZt1JUfxvxAVHiU18s2xpQvEJObiHwA/Af4XFVdFdrXn8lNRAYCLwLhwGuqekrPCxG5BkgGFFit\nqn8oq8zqTm6Fhc50aw0bwrx5ToLzVE7OL6xceR4REXU555xviYoKrvG4Vu9dzdmTz+bqDlczoOUA\nr5W75/AeHv/mcV4c+CJ3nnun18o1xnjOk+RWHXV2Oce7GPgT0Bt4D3hdVTd5tK+/kpuIhAO/AJcA\nKcBy4DpV/bnYNm2BWcCFqpouIg1VdX9Z5VZ3cpszB668EmbPhquuqvj+hw59z6pVFxAX15GuXRcS\nEVHb+0FWk8EzBrMsZRlb79xKvZh6XitXVbnkrUtYvW81W+/cSkKtBK+VbYzxTHnJrbrqbA9jqwNc\nB9wP7AKmAm+ran5p+/izQ0kvYIuqblPVPGAmMOykbcYAk1Q1HcAbX1JVvfyyMwXb0KGV2z8h4Vw6\ndJjF4cMr+fnnEbhcpf42AWXh9oV8vuVz7jv/Pq8mNgARYcLFE0jNSeW5b5/zatnGGK/xS50tIonA\naOAW4CecluM5wJdl7efP5NYUJwMXSXF/VtyZwJki8j8RWeZuEvvNzz/DV1/B//0fRFThIYqkpMs5\n88zJHDw4j02bxhDo9z1Vlb8v+DvNE5pze6/bq+UYPU7rwciOI3n+u+fZc3hPtRzDGFMlPq+zReRD\n4BsgFhiiqkNV9b+qegdQ5mWvQH8UIAJoCwzAaZJOFZFThh8WkbEiskJEVhQUFFRbMJMmQa1aTi/J\nqjrttFto2TKZffums337A1UvsBq9//P7rPhtBY9d8BjREdHVdpwnLnyCvMI8Hl38aLUdwxhTqoii\netS9jK1MGXhQZ1fARFXtoKpPqeoJf/Wqao+ydvRnctsNNC/2vpn7s+JSgI9VNV9Vt+Nc7217ckGq\nOkVVe6hqj4iqNKnKkJkJ06fDtddCgwbeKbNFi4do0mQMv/76JLt3v+KdQr0svzCf+76+j04NO3FD\nlxuq9Vit67fm1u63MnXlVH5J+6Vaj2WMOUVBUT3qXqactN5rdXYFdCieHEWknoj8xZMd/ZnclgNt\nRaSViEQB1wIfn7TNHJy/ABCRJJwm7zZfBlnkjTcgOxtu9+JVORGhbdtXSEwcwubNt3PgwAfeK9xL\npq6cypaDW5hw0QTCw8Kr/XgP9n+QmMgY7vvKJsAzJsD4o84eo6oZRW/c9/LGeLKj35KbqhYAtwPz\ngQ3ALFVdLyKPikhRd435QJqI/AwsBO5V1TRfx+pyOZcke/eGHmU2hCsuLCyCDh1mEh/fk02bxgRU\nB5PDRw/zyOJH6N+iP4PbDvbJMRvGNeTe8+5l9obZLEtZ5pNjGmPK56c6O1zk+FPE7h6bHj0Maw9x\ne2DePBg0CGbMgD9U+omNsh048AHr1w+na9eF1Ks3oHoOUkGPLHqE5MXJLLt5Gec2O9dnx83Ky6L1\nxNaclXQWi25chJT3hLwJGC518cXWL+jfoj8xkTH+DsdUQIA+xP0s0AKY7P7oz8AuVb2nvH0DvUNJ\nQHj5ZWjUCK6+uvqOUa/e7xGJIi3tk+o7SAXsy9rHs98+y/D2w32a2ABqR9Xm4f4Ps2TnEuZunuvT\nY5vKyyvM4/oPrmfQjEFc+valZORmlL+TMWUbh9MC/D/38hXwd092tORWjq1bYe5c+POfIaoaR4aK\niKhN3boXkJb2afUdpAIeW/IYuQW5PHnRk345/phzxtCmfhvGfzWeQlehX2IwnsvOy2bYzGHMXDeT\nUV1GsSxlGQPeGMC+rH3+Ds0EMVV1qeq/VfVq9zJZVT2qECy5leOVVyA83Elu1S0paQhHjvxCTo5/\newpuObiFyT9OZsw5Yzgz8Uy/xBAZHsmTFz7Juv3reGvNW36JwXgm/Ug6v3/793yx9QumDpnKm1e+\nySfXfcLmg5vp+3pfdmTs8HeIJkiJSFsReV9EfhaRbUWLJ/tacitDdjZMmwbDh8Npp1X/8RITLwfw\n+6XJ+7++n6jwKB7q/5Bf47i6w9X0PK0nDy58kCP5R/waiynZnsN76P9Gf1b8toJZV8/ilnOch0Av\nbXMpC0YtIC0njT7T+rBu/zo/R2qC1OvAv4EC4ALgTeBtT3b0KLmJyF9FJEEc/xGRlSLy+0qHGyRm\nzICMDO92/y9LdHQL4uI6k5rqv+S2fPdyZq2fxT2/u4cm8U38Fgc4j0o8c8kzpBxK4eUfvD8Tgama\nbenb6Pt6X7alb+OzP3zG8A7DT1j/u+a/Y8mflqCq9Hu9n/V+NZURo6pf4XR+3KmqycBlnuzoacvt\nJlU9BPweqAeMAk4ZDTqUqDrT2XTrBn36+O64iYlDyMxcSn5+uu8O6qaqjFswjqTYJP523t98fvyS\nDGg5gEFtBvHk0idJP+L778SUbO2+tfSZ1oeM3Ay+vvFrLj7j4hK369SwE0tvWkr9mPpc/ObFfLm1\nzOEAjTnZUREJAzaLyO0iciXlDLtVxNPkVtQXezDwlqquL/ZZSFqyBNatc1ptvuyJnpg4BCjk4MF5\nvjuo2/yt81m4YyEP9XsooEbmn3DxBDJzM5mwNKT/ngoa3+76ln5v9CNcwvnmT9/Qq2mvMrc/o94Z\nLL1pKa3rt+aydy7jvfXv+ShSEwL+ijOu5J1Ad+AG4EZPdvQ0uf0oIl/gJLf5IhIPVGjiuGDz0ktQ\nv371PddWmoSEXkRGNvD5fbdCVyHjFoyjVd1W/LmHD3rPVECXRl0Y1XUUL37/Irsyd5W/g6k287bM\n4+I3L6ZBbAP+d9P/6NCgg0f7Na7dmMWjF9OraS9Gvj+SKT+ePLKTMSdyP7A9UlWzVDVFVf+kqsNV\n1aPr254mt5uB8UBPVc0BInEmkAtJu3Y587bdfDPE+Pg5VJEwEhMv4+DBz306Wsk7a99hzb41PHHh\nEwE5G/ajAx5FUR5e9LC/Q6mxZq6byZB3h9AuqR1Lb1pKi7otKrR/3ei6fDHqCwa1HcSfP/0zT33z\nVMDPiGH8x93lv29l9/dohBIR6QOsUtVsEbkBZy6dF1V1Z2UPXF0qO0JJZm4mN398MwDr1sOmjTBw\nEMTFlrx9xwYdebD/g0SEeX+g5rJGK8nIzeC+r+5jf7Z3p7b75tdvaJbQjOVjlhMmgdmJ9m9f/I0X\nvnuBK866wqsx1oqoxbg+4+jSqIvXyvTUf9f9l7Qjafylp0djwXpk/pb57Dq061jPRW94c/WbjJ4z\nmvNbnM/H135Mneg6lS4rvzCf0R+N5p2173BRq4uoG12VQeNNcW3rt+Wpi5+q1L4BOkLJv3Gm1XkP\nOFaxq2q5A/F6WjP/G+gqIl2Be4DXcLpk9q9wtAGqUAvZmLoRVdiSDvGtYFcOkHPqti51MXvDbFbv\nW83Mq2d6fRqY4qOVFE9uew7vYeCMgWw4sMHrz5+dXud0Jg2eFLCJDeC+8+9j/YH1Xp8xYPfh3Xz2\ny2d8+odP6Xt6pf9QrLCnlz7N+K/GIwjnNT+Pbo27VbnM9CPpXDf7OjJyMzi36bl0btS5ymUePHKQ\nOz+/k/NbnM+86+dVeVityPBI3rryLVrUacHHmz5mb9beKsdoHIF41aWKooE04MJinylQ/ijzqlru\nAqx0//sQcHPxzwJtiY2N1aqYPl0VVL/8suztJv0wSSVZtP/r/TUzN7NKxyzJqlWX6rJlZx57v/Xg\nVj3jxTM07ok4/XJrOcGZCtmZsVPbvdROYx6P0c9++azaj+dyufTeL+5VktERs0ZovQn19NK3LvVK\n2X//4u8qyaLxT8br4BmDvVLmPfPvUUkWXbN3jVfKM4EJyNYAqMO9tXia3BYD/wA2A41x7tWt9Xfw\nJS1VTW49e6qedZaqy1X+tu+seUcjHo3Qcyafo/uy9lXpuCdLSXlZFy5Es7M36Zq9a7Txc4018elE\n/T7le68exzj2Z+3X7pO7azRTEN0AACAASURBVMSjEfr26rer7Tj5hfl605yblGT0ts9u00JXoT73\nv+eUZHTB1gVVKvvXjF+11mO1dNQHo/SZpc8oyejC7QurVOaO9B0a9ViUjp4zukrlmMAXiMkN5yHu\naScvHu3r4QEaA3cD57vfnw780d8nXtJSleS2bJnzjbz8suf7zP1lrsY8HqNnvnSm7kjfUeljn+zI\nkR26cCH6wfLbte6Eutr0+aa6fv96r5VvTpWZm6kXvHGBkoy+9P1LXi//SP4RvXLmlUoy+vDCh9Xl\n/gvqSP4RPf2fp2v3yd210FVY6fJvmnOTRj0WpdvTt2tOXo42e6GZ9pra69hxKuPGD2/UWo/V0p0Z\nOytdhgkOAZrchhdbrgfex5md2zvJzX2QRsDl7qWhv0+6tKUqye3661Xj41UPHarYfkt3LtW6E+pq\nsxea6c/7f6708U/24mctNfqxMG07sa1XE6cp3ZH8Izrs3WFKMpq8MLlKiaG4Q7mH9MLpFyrJ6IvL\nXjxl/fRV05VkdObamZUqf92+dRr2SJjePe/uY5+9/tPrSjL63vr3KlXm6r2rVZJF/zb/b5Xa3wSX\nQExuJy/uq4bferSthwVeA+wEpuN0JNkOXO3vEy1pqWxy27tXNTJS9Y47KrW7rt67+tilwx9Sfqhc\nIcXMXDtTIx8N07bPoSnpm6pcnvFcfmG+jp4zWklG75h7R5VaU6qqB7IPaI8pPTT8kXB9a/VbJW5T\nUFigXf7dRVu/2FqPFhyt8DGGvDNE6zxVR1OzU08os+Okjtp2YlvNK8ircJmDZwzWuhPqalpOWoX3\nNcEnSJJbO2CLR9t6WODq4q01oAGw2t8nWtJS2eSWman63HOqm6qQR7akbdFW/2qltZ+sXaX7J6/8\n8IpKsuh5U7vpJ1+ie/fOqHxQplIKXYV697y7lWT0+tnXVyo5qDr3wc56+SyNfjxaP9n0SZnbzv1l\nbqUuiS7ZsURJRp/65qlT1n2y6RMlGX3lh1cqVObC7QuVZPTppU9XaD8TvAIxuQGHgUPFll+A4R7t\n6+EB1p70PmQ7lFTV7kO7tdMrnTTqsSid/fPsCu3rcrn0scWPKcnokHeGaPbRLF26tIGuX39dNUVr\nyuJyufTJJU8qyehlMy7T7LzsCu2/8cBGbf5Cc014KkEX71js0fEGvDFAGzzTQA/lenZt3OVyae/X\neutpz59WYnwul0v7vd5PGz3bSA8fPexxmT2n9NRmLzTTnLwcj/YxwS8Qk1tVFk8faponIvNFZLSI\njAY+A2yK5BKcFn8aS0YvoXuT7ox4bwT/Wfkfj/ZzqYu759/NgwsfZFSXUcy+ZjaxUXF+Ga3EOESE\nf5z/DyZfPpm5m+dWaHbpH3/7kb6v9+Vo4VEWj15Mvxb9PDreMxc/w4GcAzz/3fMeHWfOxjksS1nG\nIwMeITby1BEHRISnL36afdn7+Od3//SozNkbZrP8t+U8OuDRKj/TZkxViMiVIlKn2Pu6InKFR/s6\nCdujgwwHisbH/0ZVP6xwpD5Q2RFKvC07L5ur37uaeVvmERNRfgXhUhdHC49y17l38fylzx97mLqs\n0UqM77y3/j2u/+B6AI9GpTlaeJTmCc35ctSXtE1sW6FjXfPeNczdPJctd26hce3GpW5X4Cqg0yud\nCJMw1vzfmjLjGj5rOF9s/YKtd26lYVzDUrfLL8yn4ysdiQqPYvWtqwkPC69Q7CZ4BegIJatUtdtJ\nn/2kqmeXt6/HY0ep6mxgdiXiq5HiouL46NqPeOn7l9iXvc+jfTo17MSoLqOQYtMQlDZaifGtER1H\ncFr8aXy06SOPto+OiObWHrdyWnzFZ7l94sIn+HDjhzy2+DEmXTap1O2m/TSNTWmbmDNyTrkJ98kL\nn+SjjR/x+JLHmThoYqnbvbbyNTYf3Mwn131iic0EgpKuLnqUt8psuYnIYZyhTk5ZBaiqBs68KG6B\n0nLzptWrB5Kbu41zz/XusFMmcN322W1MWTmFn//yc4ktv+y8bNq81IbW9VrzzZ++OeEPotLc+umt\nTPtpGhtu20Dr+q1PWZ+Vl0WbiW04M/FMFo9e7FGZJnQEaMttGpABFP2VdxtQX1VHl7dvmffcVDVe\nVRNKWOK9kdhEZKCIbBKRLSIyvozthouIikiPqh4zGCUmXs6RI5vJybHkVlM82P9BaoXX4v6v7y9x\n/b+W/Yu9WXt5+uKnPU5CD/d/mMjwSB5Y+ECJ61/47gX2Ze/jmUuescRmSuSHOvsOIA/4LzATyMVJ\ncOXy2yi57rl6JgGDgA7AdSJyyuRQ7rnj/gp879sIA0dS0hAAn8/xZvynce3G3PO7e3jv5/f4YfcP\nJ6xLzUnl6f89zbB2w+hzuufTxDeJb8Ldve9m5rqZ/Pjbjyes25+9n2e/fZar2l9F72a9vXIOJrT4\no85W1WxVHa+qPVS1p6rep6oeXZrz5xDwvXAextumqnk4WXlYCds9BjyNk7FrpOjoFsTFdSY11ZJb\nTfK38/5Gg9gGjFswjuK3Dx5f8jjZ+dk8dVHFpza5t8+9JMYknlLmY4sf40j+EZ688EmvxG5Cks/r\nbBH5UkTqFntfT0Tme7KvP5NbU6D4tMop7s+OEZFzgOaq+pkvAwtEiYlDyMxcSn5+ur9DMT4SXyue\nh/o/xKIdi5i3ZR4A29O388ryV7ip2020b9C+wmUm1ErgwX4P8tX2r/hy25cAbD24lVd/fJVbzrmF\ndkntvHoOJqT4o85OUtVjz9+oajpQenffYgJ28i4RCQNewJk/rrxtx4rIChFZUVBQUP3B+UFi4hCg\nkIMHP/d3KMaHxnYfS+t6rRm3YByFrkIeXOhMkJs8ILnSZd7a41Za1W3FuAXjcKmLBxY+QFR4FA/3\nt1nOa7iIonrUvYytyM4VqbMrwCUipxc7RktK7uR4Cn8mt91A82Lvm7k/KxIPdAIWicgOoDfwcUk3\nKFV1ivuabI+ICO/PjB0IEhJ6EhnZgLS0T/0divGhqPAonrjwCdbuX8vfv/w7M9bO4K7ed9E0oWn5\nO5eiVkQtHr/wcVbtXcW9X9zLzHUzubv33TSJb+LFyE0QKiiqR93LlJPWe63OroD7gaUi8paIvM3x\n6dfK5fFD3N4mIhE444RdhPMFLQf+oKrrS9l+EfA3VV1RVrmh+ChAkY0b/0Rq6hzOO28/YWGR/g7H\n+IhLXfSa2osf9/xI/Zj6bL1zK3Wj65a/Yzll9pjSg5/2/kRSbBJb79xKQq2Ae7LH+FB5jwJUV53t\nQVwNgbHAT0AMsF9Vl5S3n99abqpaANwOzAc2ALNUdb2IPCoiQ/0VVyBLTBxCQUEGmZn/83coxofC\nJMzpno/wUL+HqpzYTi4zuX+yJTZTLn/U2SJyC/AVzqXOvwFvAcke7euvllt1CeWWW0FBFv/7XyJN\nm95OmzaejT1oQsdvh3+r1Ignvi7TBKcAfYh7LdATWKaq3UTkLOBJVb2qvH0DtkOJOVVERG3q1r3A\nnneroaojCVliMwEuV1VzAUSklqpuxJnTrVyW3IKMjVZijKlBUtzPuc0BvhSRj3Amzi6XJbcgUzRa\nSWrqx36OxBhjqpeqXqmqGaqaDDwI/AfwaMobS25BxhmtpAtpaZbcjDE1h6ouVtWP3aOjlMuSWxBK\nShpGZub/yMtL9XcoxhgTkCy5BaHExKGAi4MHbTJ0Y4wpiSW3IBQffw5RUafZfTdjjCmFJbcgJBJG\nYuIQDh6cR2FhjZ0swRhjSmXJLUglJQ3F5comI2Ohv0MxxpiAY8ktSNWteyFhYXHWa9IYY0pgyS1I\nhYdHU7/+paSmfkyoDaFmjDFVZcktiCUlDSUv7zeyslb6OxRjjAkoltyCWP36lwFh1mvSGGNOYskt\niEVFJVGnTh9SUz/ydyjGGBNQLLkFucTEoWRnryY316OxRI0xpkaw5BbkkpKcOQJTU20aHGOMKWLJ\nLcjFxp5JTEw7eyTAGGOKseQWApKShpKRsYiCgkx/h2KMMQHBklsISEoahmo+Bw/O83coxhgTECy5\nhYCEhN5ERibZIwHGGONmyS0EiISTmHg5Bw/OxeXK93c4xhjjd5bcQkRi4lAKCjLIzFzq71CMMcbv\nLLmFiPr1f49ILXug2xhj8HNyE5GBIrJJRLaIyPgS1t8tIj+LyBoR+UpEWvgjzmAQHh5HvXoXk5Zm\nAykbY6pHMNXZfktuIhIOTAIGAR2A60Skw0mb/QT0UNUuwPvAM76NMrgkJQ0lN3c72dnr/R2KMSbE\nBFud7c+WWy9gi6puU9U8YCYwrPgGqrpQVXPcb5cBzXwcY1BJTLwcwB7oNsZUh6Cqs/2Z3JoCu4q9\nT3F/Vpqbgc9LWiEiY0VkhYisKCgo8GKIwaVWrdOIj+9pjwQYYyojoqgedS9jT1rvtTrbFyL8deCK\nEJEbgB5A/5LWq+oUYApAXFxcjb7hlJQ0jO3bH+Do0T3UqtXE3+EYY4JHgar28EZB5dXZvuDPlttu\noHmx983cn51ARC4G7geGqupRH8UWtBITnYGU09I+9XMkxpgQE1R1tj+T23KgrYi0EpEo4FrghOtp\nInI2MBnnS9rvhxiDTlxcJ6KjW9p9N2OMtwVVne235KaqBcDtwHxgAzBLVdeLyKMiMtS92bNAbeA9\nEVklIlZjl0NESEwcSnr6AgoLs/0djjEmRARbnS2h9kxUXFycZmfX7Eo9Pf1rVq++iE6d5pCUNKz8\nHYwxNZ6I5KhqnL/j8BYboSQE1alzPuHhdWy0EmNMjWXJLQSFhUWSmDiYtLRPUS30dzjGGONzltxC\nVGLiUPLzD3Do0Pf+DsUYY3zOkluIql9/ICIR9kC3MaZGsuQWoiIj61K37gD273+HvLxUf4djjDE+\nZckthLVo8TD5+QdYs+b35Odn+DscY4zxGUtuIaxu3b507PgB2dnrWLt2EAUFh/0dkjHG+IQltxCX\nmDiIDh3+y6FDy1m7dgiFhTnl72SMMUHOklsN0KDBlbRv/xaZmUtYt+4qXC4botMYE9osudUQjRpd\nR7t2r5GePp/160ficuX7OyRjjKk2ltxqkCZNbqJNm5dIS/uIDRtG2QPexpiQFRTzuRnvadbsdlyu\nHLZtG8emTTG0a/cfROxvHGNMaLHkVgOdfvrfKSzMYefORwgLi6Vt25cREX+HZYwxXmPJrYZq2fJh\nXK4cdu16lvDwWM444xlLcMaYkGHJrYYSEc4442kKC3PYtes5wsLiaNUq2d9hGWOMV1hyq8FEhLZt\nJ+JyOZcoc3O30br1s0RFNfJ3aMYYUyXWk6CGEwmjXbupnH76/ezfP5Pvvz+TlJSXcLkK/B2aMcZU\nms3EbY7JydnE5s23k56+gNq1u9G27SvUqfM7f4dljPGBUJuJu0Ykt/z8fFJSUsjNzfVTVMGlsDCb\ngoJ0VPOJiMijdevexMY29ndYxphqFGrJrUbcc0tJSSE+Pp6WLVtaj0APqRaSm/sbqam/sWHDhzRu\nDKedNhaRcK8ep7Awl/T0BRQWZpGYeDkREbW9Wr4xpmaqEcktNzfXElsFiYQTE9OcJk0SOXgwm82b\nL2Lv3mm0bfsKCQk9q1R2fn4GBw9+RmrqHNLSPsflclraYWFxNGgwnMaNb6Ru3QH2cLkxptJqRHID\nLLFVUkRELFFRTWjf/h22br2HlSvPJSlpGHFxXYmNbUtMzJnExLQlMrJumeUcPfobqakfkZo6h4yM\nr1EtICqqCY0bjyIp6QrCwmLZt+9N9u+fxb59b1Kr1uk0bvxHGjW6kdjYNj46W2NMqPDrPTcRGQi8\nCIQDr6nqhJPW1wLeBLoDacBIVd1RVpkl3XPbsGED7du392LkNUvR91dQcIgdOx7hwIHZHD36K3D8\nv53IyAbExJx5QsKrVaspmZlLSE2dw6FDywCIiWlLUtKVJCVdSUJCr1NaZ4WFR0hNncPevdNJT/8S\ncJGQcB6NG99IgwbXlJtEAVTVPfOBEhYWbX/YGOMBT+65VUedXV38ltzEuXnzC3AJkAIsB65T1Z+L\nbfMXoIuq3ioi1wJXqurIssoNxOSWkZHBO++8w1/+8pcK7zt48GDeeecd6tYtv1KvLiV9f4WFueTm\nbiMn5xeOHNnMkSO/kJPj/JuXt+eEbePje5CUdAVJSVcSG9ve42Rz9Ohu9u17m717p5OTs4GwsGj3\nfbl6FBZmFVsOn/Q+C1XnUQaRCMLD6xARUbTUJSKizkmf1XEnwSjCwqJK+bcWIlGIRLgTchgi4cVe\nl/RvSedZ2rm7cP5fdBZV17HXJ76viOLxSCnxhaFacNKSX+JrUPf5R7r/Pfl18fdS7Fyd18d/dym2\nqLv8QqDw2GtnKf55ofv7jgDCix0v/KTjO/eEVfNxufLd8ee73+cVe+2c1/H9Sy/TOV54sXOQk84p\n7KR1xR3/zTyta0v+/8PTP9DCCA+P9nDbU45bZnKrrjq7uvgzuf0OSFbVS93v/wGgqk8V22a+e5vv\nxPmvbC/QQMsIOhCT244dO7j88stZt27dKesKCgqIiAjsq8MV/f4KCrI4cmQLR4/upHbtc4iObl6l\n46sqhw+vYO/e6aSmfgi4CA+vXWyJL/E9CIWFmRQUHF9OfJ9BYeFhKp40jAlM8fHn0r37skrt60Fy\nq5Y6u7r4s1ZtCuwq9j4FOLe0bVS1QEQygUQgtfhGIjIWGAsQFRVV5kHvugtWrapS3Kfo1g3+9a/S\n148fP56tW7fSrVs3LrnkEi677DIefPBB6tWrx8aNG/nll1+44oor2LVrF7m5ufz1r39l7NixALRs\n2ZIVK1aQlZXFoEGD6Nu3L99++y1Nmzblo48+IiYm5oRjffLJJzz++OPk5eWRmJjIjBkzaNSoEVlZ\nWdxxxx2sWLECEeHhhx9m+PDhzJs3j/vuu4/CwkKSkpL46quvqvx9RETUJj6+G/Hx3apcFjh/ySYk\n9CQhoSdnnvmyV8osouqisDALl+soqnnuv+6df0v6TDUfp7VRiNPacpXyb0nTCZX8/7eqFmtJyUmv\ny2sZlHpm7pbC8ZiOtwCLx6nulsqJLbCwsFNbZ06spbXwCo61hoq+oxPjOP7++GeO462louV4a+n4\n+zB3vEUtu4ITXh9v9RW12COPLc65RLpb4JHF1kUUK7Pkcou/P7ElrZTcstYSfiMp5XXJv5tnn5Us\nKqqJx9uWIEJEVhR7P0VVpxR777U62xcCu8ngIfcPMAWclpufwznFhAkTWLduHavcWXXRokWsXLmS\ndevW0apVKwCmTZtG/fr1OXLkCD179mT48OEkJiaeUM7mzZt59913mTp1Ktdccw2zZ8/mhhtuOGGb\nvn37smzZMkSE1157jWeeeYbnn3+exx57jDp16rB27VoA0tPTOXDgAGPGjGHJkiW0atWKgwcP+uDb\nCCwiYUREJPg7DGMCQYGq9vB3EN7iz+S2Gyh+vaqZ+7OStklxN3Hr4NykrLSyWli+1KtXr2OJDWDi\nxIl8+OGHAOzatYvNmzefktxatWpFt25Oa6h79+7s2LHjlHJTUlIYOXIke/bsIS8v79gxFixYwMyZ\nM49tV69ePT755BP69et3bJv69et79RyNMSHFL3V2ZfnzQaLlQFsRaSUiUcC1wMcnbfMxcKP79dXA\n1/64dlsd4uKOX9petGgRCxYs4LvvvmP16tWcffbZJY6mUqtWrWOvw8PDKSg4dfzHO+64g9tvv521\na9cyefJkG5XFGOMtQVVn+y25qXNx/HZgPrABmKWq60XkUREZ6t7sP0CiiGwB7gbG+yfaqomPj+fw\n4cOlrs/MzKRevXrExsayceNGli2r3A3horKaNm0KwPTp0499fskllzBp0qRj79PT0+nduzdLlixh\n+/btADXysqQxxjPBVmf79Z6bqs4F5p702UPFXucCI3wdl7clJibSp08fOnXqxKBBg7jssstOWD9w\n4EBeffVV2rdvT7t27ejdu3elj5WcnMyIESOoV68eF1544bHE9cADD3DbbbfRqVMnwsPDefjhh7nq\nqquYMmUKV111FS6Xi4YNG/Lll19W6VyNMaErmOrsGjFwsr8fBQh29v0ZE/pCbeBkG7zPGGNMyLHk\nZowxJuRYcjPGGBNyLLkZY4wJOZbcjDHGhBxLbsYYY0KOJbcAVbt2bX+HYIwxQcuSmzHGmJATErMC\nVMRd8+5i1V7vznnTrXE3/jWw9BGZx48fT/PmzbntttsAZxSR2rVrc+uttzJs2DDS09PJz8/n8ccf\nZ9iwYWUeq7SpcUqauqa0aW6MMSbU1bjk5g8jR47krrvuOpbcZs2axfz584mOjubDDz8kISGB1NRU\nevfuzdChQ8ucqbqkqXFcLleJU9eUNM2NMcbUBDUuuZXVwqouZ599Nvv37+e3337jwIED1KtXj+bN\nm5Ofn899993HkiVLCAsLY/fu3ezbt4/GjRuXWlZJU+McOHCgxKlrSprmxhhjaoIal9z8ZcSIEbz/\n/vvs3buXkSNHAjBjxgwOHDjAjz/+SGRkJC1btixzipriU+PExsYyYMAAm9LGGGNKYB1KfGTkyJHM\nnDmT999/nxEjnEGzMzMzadiwIZGRkSxcuJCdO3eWWUZpU+OUNnVNSdPcGGNMTWDJzUc6duzI4cOH\nadq0KU2aNAHg+uuvZ8WKFXTu3Jk333yTs846q8wyBg4cSEFBAe3bt2f8+PHHpsZp0KDBsalrunbt\neqxl+MADD5Cenk6nTp3o2rUrCxcurN6TNMaYAGFT3phy2fdnTOizKW+MMcaYAGfJzRhjTMipMckt\n1C6/+op9b8aYYFQjklt0dDRpaWlWUVeQqpKWlkZ0dLS/QzHGmAqpEc+5NWvWjJSUFA4cOODvUIJO\ndHQ0zZo183cYxhhTITWit6QxxpiyWW9JLxCR+iLypYhsdv97yrhQItJNRL4TkfUiskZERvojVmOM\nMWULxDrdX/fcxgNfqWpb4Cv3+5PlAH9U1Y7AQOBfIlLXhzEaY4zxTMDV6X65LCkim4ABqrpHRJoA\ni1S1XTn7rAauVtXNZW1nlyWNMabiqnJZsjrr9MryV4eSRqq6x/16L9CorI1FpBcQBWwtZf1YYKz7\nrYrIkSrEFgEUVGH/QBNq5wOhd06hdj4QeucUaucDp55TjIisKPZ+iqpO8bAsr9bp3lBtyU1EFgAl\nzd1yf/E3qqoiUmrz0f1XwFvAjarqKmkb9w/g6Y9QJhFZoao9vFFWIAi184HQO6dQOx8IvXMKtfOB\nip+TL+t0b6i25KaqF5e2TkT2iUiTYk3Y/aVslwB8BtyvqsuqKVRjjDHlCLY63V8dSj4GbnS/vhH4\n6OQNRCQK+BB4U1Xf92FsxhhjKibg6nR/JbcJwCUishm42P0eEekhIq+5t7kG6AeMFpFV7qWbD2Lz\nyuXNABJq5wOhd06hdj4QeucUaucD3j2ngKvTQ+4hbmOMMaZGjC1pjDGmZrHkZowxJuRYcnMTkYEi\nsklEtohISU/XBx0R2SEia93XtleUv0dgEZFpIrJfRNYV+6zcYX4CWSnnlCwiu4vdhxjszxgrQkSa\ni8hCEfnZPazSX92fB+XvVMb5BPNvFC0iP4jIavc5PeL+vJWIfO+u8/7r7vARMuyeGyAi4cAvwCVA\nCrAcuE5Vf/ZrYFUkIjuAHqqa6u9YKkNE+gFZOL2rOrk/ewY4qKoT3H+E1FPVcf6MsyJKOadkIEtV\nn/NnbJXh7vbdRFVXikg88CNwBTCaIPydyjifawje30iAOFXNEpFIYCnwV+Bu4ANVnSkirwKrVfXf\n/ozVm6zl5ugFbFHVbaqaB8wEhvk5phpPVZcAB0/6eBgw3f16Ok7FEzRKOaegpap7VHWl+/VhYAPQ\nlCD9nco4n6Cljiz320j3osCFQFGX/KD5jTxlyc3RFNhV7H0KQf4ftJsCX4jIj+4hykJBhYb5CSK3\nu0dKnxYsl/BOJiItgbOB7wmB3+mk84Eg/o1EJFxEVuE8XP0lzrBXGapaNPxWqNR5x1hyC219VfUc\nYBBwm/uSWMhQ55p6KFxX/zfQGugG7AGe9284FScitYHZwF2qeqj4umD8nUo4n6D+jVS1UFW7Ac1w\nrlSd5eeQqp0lN8duoHmx983cnwU1Vd3t/nc/zsgAvfwbkVfsc98XKbo/UuIwP8FEVfe5Kx8XMJUg\n+53c93FmAzNU9QP3x0H7O5V0PsH+GxVR1QxgIfA7oK6IFA3BGBJ1XnGW3BzLgbbu3kNRwLU4w8kE\nLRGJc98QR0TigN8D68reKyiUO8xPsClKAm5XEkS/k7uzwn+ADar6QrFVQfk7lXY+Qf4bNRD3vGki\nEoPTcW4DTpK72r1Z0PxGnrLekm7urr3/AsKBaar6hJ9DqhIROQOntQbOANnvBNs5ici7wAAgCdgH\nPAzMAWYBpwM7gWtUNWg6aJRyTgNwLncpsAP4c7H7VQFNRPoC3wBrgaIR3u/DuU8VdL9TGedzHcH7\nG3XB6TASjtOgmaWqj7rriJlAfeAn4AZVPeq/SL3LkpsxxpiQY5cljTHGhBxLbsYYY0KOJTdjjDEh\nx5KbMcaYkGPJzRhjTMix5GZMABGRASLyqb/jMCbYWXIzxhgTciy5GVMJInKDe46sVSIy2T0wbZaI\n/NM9Z9ZXItLAvW03EVnmHnT3w6JBd0WkjYgscM+ztVJEWruLry0i74vIRhGZ4R41wxhTAZbcjKkg\nEWkPjAT6uAejLQSuB+KAFaraEViMM/oIwJvAOFXtgjPyRdHnM4BJqtoVOA9nQF5wRqK/C+gAnAH0\nqfaTMibERJS/iTHmJBcB3YHl7kZVDM7AwC7gv+5t3gY+EJE6QF1VXez+fDrwnnvcz6aq+iGAquYC\nuMv7QVVT3O9XAS1xJpg0xnjIkpsxFSfAdFX9xwkfijx40naVHduu+Ph+hdj/p8ZUmF2WNKbivgKu\nFpGGACJSX0Ra4Pz/VDTK+h+ApaqaCaSLyPnuz0cBi92zPKeIyBXuMmqJSKxPz8KYEGZ/ERpTQar6\ns4g8gDPLeRiQD9wGvgfU0AAAAGtJREFUZAO93Ov249yXA2c6kVfdyWsb8Cf356OAySLyqLuMET48\nDWNCms0KYIyXiEiWqtb2dxzGGLssaYwxJgRZy80YY0zIsZabMcaYkGPJzRhjTMix5GaMMSbkWHIz\nxhgTciy5GWOMCTn/H4yJ1VKYABieAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL9oFs6WEru4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model - 파일명에 정확도.\n",
        "\n",
        "model.save('/content/drive/My Drive/final/111_%.2f.h5' % (accuracy*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHCGw_ITfPLi",
        "colab_type": "text"
      },
      "source": [
        "https://lsjsj92.tistory.com/353\n",
        "\n",
        "리뷰당 Max 패딩 길이는 긴데. 정작 대부분의 리뷰의 길이는 짧음.\n",
        "같은 레이블(별점)을 갖는 리뷰들을 각각 3~5개?씩 합쳐보는 건 어떤지?\n",
        "\n",
        "\n",
        "=> 우리 리뷰의 경우도  Max=142 길이로 zero 패딩해뒀는데\n",
        "출력해보니 대부분의 리뷰는 XX 두자리수 길이였음.(대략 20~30)\n"
      ]
    }
  ]
}